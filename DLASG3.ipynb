{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyvJ9p6A9daBBaipSjp7Vy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manasdeshpande125/da6401_assignment_3/blob/main/DLASG3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWnRcWPc2bK4"
      },
      "outputs": [],
      "source": [
        "import torch, os, random, numpy as np, pandas as pd\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download dataset and unzip it**"
      ],
      "metadata": {
        "id": "XajVkf9mJ3dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request, tarfile, pathlib, shutil\n",
        "\n",
        "URL = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "TAR = \"dakshina.tar\"\n",
        "if not pathlib.Path(TAR).exists():\n",
        "    urllib.request.urlretrieve(URL, TAR)\n",
        "    print(\"Downloaded.\")\n",
        "\n",
        "with tarfile.open(TAR) as t:\n",
        "    members = [m for m in t.getmembers() if m.name.startswith(\"dakshina_dataset_v1.0/mr/lexicons/\")]\n",
        "    t.extractall(members=members)\n",
        "DATA_ROOT = pathlib.Path(\"dakshina_dataset_v1.0/mr/lexicons\")\n",
        "print(\"Files:\", os.listdir(DATA_ROOT))"
      ],
      "metadata": {
        "id": "adGlzJff_j-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classes for loading and preparing the dataset**"
      ],
      "metadata": {
        "id": "9-3EYlsdJ8h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, file_path, src_lang, trg_lang):\n",
        "        df = pd.read_csv(file_path, sep=\"\\t\", header=None,\n",
        "                         names=[src_lang, trg_lang], dtype=str).dropna()\n",
        "        self.df = df\n",
        "        self.src_lang, self.trg_lang = src_lang, trg_lang\n",
        "\n",
        "        self.src_vocab = {c: i+3 for i, c in enumerate(sorted(set(\"\".join(df[src_lang]))))}\n",
        "        self.trg_vocab = {c: i+3 for i, c in enumerate(sorted(set(\"\".join(df[trg_lang]))))}\n",
        "\n",
        "        for v in (self.src_vocab, self.trg_vocab):\n",
        "            v[\"<pad>\"] = 1; v[\"<unk>\"] = 2; v[\"<s>\"] = 0\n",
        "\n",
        "        self.s_char2idx, self.s_idx2char = self.src_vocab, {i: c for c, i in self.src_vocab.items()}\n",
        "        self.t_char2idx, self.t_idx2char = self.trg_vocab, {i: c for c, i in self.trg_vocab.items()}\n",
        "\n",
        "    def get(self):\n",
        "        return (self.src_vocab, self.trg_vocab,\n",
        "                self.t_char2idx, self.t_idx2char,\n",
        "                self.s_char2idx, self.s_idx2char)\n"
      ],
      "metadata": {
        "id": "Bgz28A8H_nlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, file_path, src_lang, trg_lang,\n",
        "                 src_vocab, trg_vocab, t_char2idx):\n",
        "        df = pd.read_csv(file_path, sep=\"\\t\", header=None,\n",
        "                         names=[src_lang, trg_lang], dtype=str).dropna()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.src_vocab, self.trg_vocab = src_vocab, trg_vocab\n",
        "        self.t_char2idx = t_char2idx\n",
        "        self.max_src_len = df[src_lang].str.len().max() + 1\n",
        "        self.max_trg_len = df[trg_lang].str.len().max() + 1\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def _encode(self, word, vocab, max_len):\n",
        "        seq = [vocab.get(c, vocab[\"<unk>\"]) for c in word]\n",
        "        seq = [vocab[\"<s>\"]] + seq + [vocab[\"<pad>\"]] * (max_len-len(seq)-1)\n",
        "        return torch.tensor(seq, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        # src = self._encode(row[0], self.src_vocab, self.max_src_len)\n",
        "        # trg = self._encode(row[1], self.trg_vocab, self.max_trg_len)\n",
        "        # return src, trg, len(row[0])+1, len(row[1])+1\n",
        "        src = self._encode(row.iloc[0], self.src_vocab, self.max_src_len)\n",
        "        trg = self._encode(row.iloc[1], self.trg_vocab, self.max_trg_len)\n",
        "        return src, trg, len(row.iloc[0])+1, len(row.iloc[1])+1\n"
      ],
      "metadata": {
        "id": "zL1lEd3Q_qj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class DakshinaDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size=128):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_path = DATA_ROOT/\"mr.translit.sampled.train.tsv\"\n",
        "        self.dev_path   = DATA_ROOT/\"mr.translit.sampled.dev.tsv\"\n",
        "        self.test_path  = DATA_ROOT/\"mr.translit.sampled.test.tsv\"\n",
        "\n",
        "    def prepare_data(self): pass  # Nothing to download (done above)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        vocab = Vocabulary(self.train_path, 'src', 'trg')\n",
        "        (self.src_vocab, self.trg_vocab,\n",
        "         self.t_char2idx, self.t_idx2char,\n",
        "         self.s_char2idx, self.s_idx2char) = vocab.get()\n",
        "\n",
        "        self.train_ds = TransliterationDataset(self.train_path, 'src', 'trg',\n",
        "                                               self.src_vocab, self.trg_vocab,\n",
        "                                               self.t_char2idx)\n",
        "        self.val_ds   = TransliterationDataset(self.dev_path,  'src', 'trg',\n",
        "                                               self.src_vocab, self.trg_vocab,\n",
        "                                               self.t_char2idx)\n",
        "        self.test_ds  = TransliterationDataset(self.test_path, 'src', 'trg',\n",
        "                                               self.src_vocab, self.trg_vocab,\n",
        "                                               self.t_char2idx)\n",
        "\n",
        "    def train_dataloader(self): return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True)\n",
        "    def val_dataloader(self):   return DataLoader(self.val_ds,   batch_size=self.batch_size)\n",
        "    def test_dataloader(self):  return DataLoader(self.test_ds,  batch_size=self.batch_size)\n"
      ],
      "metadata": {
        "id": "yUKtYSHe_tbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# def make_rnn(cell_type, *args, **kw):\n",
        "#     return {\"rnn\": nn.RNN,\n",
        "#             \"lstm\": nn.LSTM,\n",
        "#             \"gru\": nn.GRU}[cell_type.lower()](*args, **kw)\n",
        "\n",
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self, input_dim, emb_dim, hid_dim, n_layers, cell, dropout):\n",
        "#         super().__init__()\n",
        "#         self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "#         self.rnn = make_rnn(cell, emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=False)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#     def forward(self, src):\n",
        "#         emb = self.dropout(self.embedding(src))\n",
        "#         return self.rnn(emb)\n",
        "\n",
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, output_dim, emb_dim, hid_dim, n_layers, cell, dropout):\n",
        "#         super().__init__()\n",
        "#         self.output_dim = output_dim\n",
        "#         self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "#         self.rnn = make_rnn(cell, emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=False)\n",
        "#         self.fc = nn.Linear(hid_dim, output_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#     def forward(self, inp, hidden):\n",
        "#         emb = self.dropout(self.embedding(inp))\n",
        "#         out, hidden = self.rnn(emb, hidden)\n",
        "#         pred = F.log_softmax(self.fc(out.squeeze(0)), dim=1)\n",
        "#         return pred, hidden\n",
        "\n",
        "# class Seq2SeqLightning(pl.LightningModule):\n",
        "#     def __init__(self, src_vocab, trg_vocab,\n",
        "#                  emb_dim=128, hid_dim=256, n_layers=2,\n",
        "#                  cell=\"lstm\", dropout=0.2, lr=1e-3, tf_ratio=0.5):\n",
        "#         super().__init__()\n",
        "#         self.save_hyperparameters()\n",
        "#         self.encoder = Encoder(len(src_vocab), emb_dim, hid_dim, n_layers, cell, dropout)\n",
        "#         self.decoder = Decoder(len(trg_vocab), emb_dim, hid_dim, n_layers, cell, dropout)\n",
        "#         self.criterion = nn.NLLLoss(ignore_index=trg_vocab[\"<pad>\"])\n",
        "#         self.tf_ratio = tf_ratio\n",
        "\n",
        "#     def forward(self, src, trg, teacher_forcing=0.5):\n",
        "#         batch, trg_len = src.shape[1], trg.shape[0]\n",
        "#         outputs = torch.zeros(trg_len, batch, len(self.decoder.embedding.weight)).to(src.device)\n",
        "#         enc_out, hidden = self.encoder(src)\n",
        "#         inp = trg[0].unsqueeze(0)\n",
        "#         for t in range(1, trg_len):\n",
        "#             pred, hidden = self.decoder(inp, hidden)\n",
        "#             outputs[t] = pred\n",
        "#             inp = trg[t].unsqueeze(0) if (torch.rand(1) < teacher_forcing) else pred.argmax(1).unsqueeze(0)\n",
        "#         return outputs\n",
        "\n",
        "#     def _step(self, batch, stage):\n",
        "#         src, trg, _, _ = batch\n",
        "#         src, trg = src.permute(1,0), trg.permute(1,0)\n",
        "#         logits = self(src, trg, self.tf_ratio if stage==\"train\" else 0.0)\n",
        "#         loss = self.criterion(logits[1:].reshape(-1, logits.shape[2]),\n",
        "#                               trg[1:].reshape(-1))\n",
        "#         self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
        "#         return loss\n",
        "\n",
        "#     def training_step(self, batch, _):   return self._step(batch, \"train\")\n",
        "#     def validation_step(self, batch, _): self._step(batch, \"val\")\n",
        "#     def test_step(self, batch, _):       self._step(batch, \"test\")\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
        "\n",
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self, input_dim, emb_dim, hid_dim, n_layers, cell, dropout):\n",
        "#         super().__init__()\n",
        "#         self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "#         self.rnn       = make_rnn(cell, emb_dim, hid_dim, n_layers,\n",
        "#                                   dropout=dropout, batch_first=False)\n",
        "#         self.dropout   = nn.Dropout(dropout)\n",
        "#     def forward(self, src):\n",
        "#         return self.rnn(self.dropout(self.embedding(src)))\n",
        "\n",
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, output_dim, emb_dim, hid_dim, n_layers, cell, dropout):\n",
        "#         super().__init__()\n",
        "#         self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "#         self.rnn       = make_rnn(cell, emb_dim, hid_dim, n_layers,\n",
        "#                                   dropout=dropout, batch_first=False)\n",
        "#         self.fc        = nn.Linear(hid_dim, output_dim)\n",
        "#         self.dropout   = nn.Dropout(dropout)\n",
        "#     def forward(self, inp, hidden):\n",
        "#         emb = self.dropout(self.embedding(inp))\n",
        "#         out, hidden = self.rnn(emb, hidden)\n",
        "#         pred = F.log_softmax(self.fc(out.squeeze(0)), dim=1)\n",
        "#         return pred, hidden"
      ],
      "metadata": {
        "id": "EjcQrP0q_vZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder, Decoder and Seq2Seq Classes for Transliteration**"
      ],
      "metadata": {
        "id": "eI96-FC7KC8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn, torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "def make_rnn(cell_type, *args, **kw):\n",
        "    return {\"rnn\": nn.RNN, \"lstm\": nn.LSTM, \"gru\": nn.GRU}[cell_type.lower()](*args, **kw)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim: int, embed_dim: int,\n",
        "                 hid_dim: int, n_layers: int,\n",
        "                 cell_type: str = \"lstm\",\n",
        "                 bidirectional: bool = False,\n",
        "                 dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.hid_dim, self.n_layers = hid_dim, n_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dir = 2 if bidirectional else 1\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "        rnn_cls = {\"rnn\": nn.RNN, \"gru\": nn.GRU, \"lstm\": nn.LSTM}[cell_type.lower()]\n",
        "        self.rnn = rnn_cls(embed_dim, hid_dim, n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout=dropout if n_layers > 1 else 0.0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type.lower()\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src ⇒ [seq_len, batch]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        return self.rnn(embedded)       # (output, hidden[, cell])\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, trg_vocab, output_dim, embed_dim, hid_dim, n_layers,\n",
        "                 cell_type: str = \"lstm\", bidirectional: bool = False, dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.trg_vocab = trg_vocab  # store it here for loss\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
        "        rnn_cls = {\"rnn\": nn.RNN, \"gru\": nn.GRU, \"lstm\": nn.LSTM}[cell_type.lower()]\n",
        "        self.rnn = rnn_cls(embed_dim, hid_dim, n_layers,\n",
        "                           dropout=dropout if n_layers > 1 else 0.0)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "    def forward(self, inp, hidden):\n",
        "        # inp ⇒ [1, batch]\n",
        "        embedded = self.dropout(self.embedding(inp))\n",
        "        outputs = self.rnn(embedded, hidden)\n",
        "        rnn_out, hidden = outputs if self.cell_type != \"lstm\" else (outputs[0], outputs[1])\n",
        "        logits = self.fc_out(rnn_out.squeeze(0))\n",
        "        return F.log_softmax(logits, dim=1), hidden\n",
        "\n",
        "class Seq2SeqLightning(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder: Encoder,\n",
        "        decoder: Decoder,\n",
        "        cell_type: str = \"lstm\",\n",
        "        bidirectional: bool = False,\n",
        "        device: str = \"cpu\",\n",
        "        learning_rate: float = 1e-3,\n",
        "        optim_name: str = \"adam\",\n",
        "        tf_ratio: float = 0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optim_name = optim_name.lower()\n",
        "        self.tf_ratio = tf_ratio\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index=decoder.trg_vocab[\"<pad>\"])\n",
        "        self.pad_idx = decoder.trg_vocab[\"<pad>\"]\n",
        "        # self.device = device\n",
        "\n",
        "    def _merge_bidir(self, h):\n",
        "        \"\"\"Average the fwd & bwd hidden states so that\n",
        "           [layers*dir, batch, hid] → [layers, batch, hid]\"\"\"\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type == \"lstm\":\n",
        "                # h is tuple(hidden, cell)\n",
        "                hidden = (h[0].view(self.decoder.rnn.num_layers, 2, -1, h[0].size(-1)).mean(1),\n",
        "                          h[1].view(self.decoder.rnn.num_layers, 2, -1, h[1].size(-1)).mean(1))\n",
        "            else:\n",
        "                hidden = h.view(self.decoder.rnn.num_layers, 2, -1, h.size(-1)).mean(1)\n",
        "        else:\n",
        "            hidden = h\n",
        "        return hidden\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size, trg_len = src.size(1), trg.size(0)\n",
        "        vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(trg_len, batch_size, vocab_size, device=self.device)\n",
        "\n",
        "        enc_out, enc_hidden = self.encoder(src)\n",
        "        dec_hidden = self._merge_bidir(enc_hidden)\n",
        "\n",
        "        # first decoder input = <sos>\n",
        "        dec_inp = trg[0].unsqueeze(0)\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            dec_out, dec_hidden = self.decoder(dec_inp, dec_hidden)\n",
        "            outputs[t] = dec_out\n",
        "            top1 = dec_out.argmax(1)\n",
        "            teacher = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            dec_inp = trg[t].unsqueeze(0) if teacher else top1.unsqueeze(0)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        learning_rate  = self.learning_rate\n",
        "        opt = self.optim_name.lower()          # \"adam\" | \"nadam\"\n",
        "\n",
        "        if opt == \"adam\":\n",
        "            optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        elif opt == \"nadam\":\n",
        "            optimizer = torch.optim.NAdam(self.parameters(), lr=learning_rate)\n",
        "        else:                                     # fallback / safety\n",
        "            raise ValueError(f\"Unknown optimizer '{opt}'\")\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def _accuracy(self, logits, trg):\n",
        "        # logits, trg both exclude <s>\n",
        "        pred = logits.argmax(1)\n",
        "        correct = (pred == trg) & (trg != self.pad_idx)\n",
        "        return correct.float().sum()/ (trg != self.pad_idx).float().sum()\n",
        "\n",
        "    def _step(self, batch, stage):\n",
        "        src, trg, _, _ = batch\n",
        "        src, trg = src.permute(1,0), trg.permute(1,0)\n",
        "\n",
        "        logits = self(src, trg, self.tf_ratio if stage==\"train\" else 0.0)\n",
        "        loss   = self.criterion(logits[1:].reshape(-1, logits.shape[2]),\n",
        "                                trg[1:].reshape(-1))\n",
        "\n",
        "        acc    = self._accuracy(logits[1:].reshape(-1, logits.shape[2]),\n",
        "                                trg[1:].reshape(-1))\n",
        "\n",
        "        self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
        "        self.log(f\"{stage}_acc\",  acc,  prog_bar=True)\n",
        "\n",
        "        # print once per epoch (on first batch)\n",
        "        # if self.trainer.is_global_zero and self.current_epoch is not None and self.global_step % self.trainer.num_training_batches == 0:\n",
        "        #     print(f\"[epoch {self.current_epoch:02d}] {stage.upper()} \"\n",
        "        #           f\"loss: {loss.item():.4f}  acc: {acc.item()*100:.2f}%\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, _):   return self._step(batch, \"train\")\n",
        "    def validation_step(self, batch, _): self._step(batch, \"val\")\n",
        "    def test_step(self, batch, _):       self._step(batch, \"test\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8egZusJZ_zIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pytorch_lightning import Trainer\n",
        "# from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# def run_training(hparams):\n",
        "#     dm = DakshinaDataModule(batch_size=hparams[\"batch_size\"])\n",
        "#     dm.prepare_data(); dm.setup()\n",
        "\n",
        "#     model = Seq2SeqLightning(dm.src_vocab, dm.trg_vocab,\n",
        "#                              emb_dim=hparams[\"emb_dim\"],\n",
        "#                              hid_dim=hparams[\"hid_dim\"],\n",
        "#                              n_layers=hparams[\"n_layers\"],\n",
        "#                              cell=hparams[\"cell\"],\n",
        "#                              dropout=hparams[\"dropout\"],\n",
        "#                              lr=hparams[\"lr\"],\n",
        "#                              tf_ratio=hparams[\"tf_ratio\"])\n",
        "\n",
        "#     ckpt = ModelCheckpoint(monitor=\"val_loss\", save_top_k=1, mode=\"min\")\n",
        "#     trainer = Trainer(max_epochs=hparams[\"epochs\"],\n",
        "#                       callbacks=[ckpt],\n",
        "#                       accelerator=\"auto\", devices=1)\n",
        "#     trainer.fit(model, dm)\n",
        "#     trainer.test(model, dm)\n",
        "\n",
        "# default_hparams = dict(batch_size=128, emb_dim=128, hid_dim=256,\n",
        "#                        n_layers=2, cell=\"lstm\", dropout=0.2,\n",
        "#                        lr=1e-3, tf_ratio=0.5, epochs=10)\n",
        "\n",
        "# run_training(default_hparams)\n",
        "\n",
        " #################################################################################################################\n",
        "\n",
        "# def run_training(hparams: dict):\n",
        "#     \"\"\"\n",
        "#     Train + evaluate one experiment using the hyper-parameters coming either\n",
        "#     from the sweep or from the manual `default_hparams` below.\n",
        "#     \"\"\"\n",
        "#     # 1) Data\n",
        "#     dm = DakshinaDataModule(batch_size=hparams[\"batch_size\"])\n",
        "#     dm.prepare_data(); dm.setup()\n",
        "\n",
        "#     # 2) Model\n",
        "#     model = Seq2SeqLightning(\n",
        "#         src_vocab        = dm.src_vocab,\n",
        "#         trg_vocab        = dm.trg_vocab,\n",
        "#         emb_dim          = hparams[\"embedding_size\"],\n",
        "#         hid_dim          = hparams[\"hidden_size\"],\n",
        "#         n_layers         = hparams[\"num_layers\"],\n",
        "#         cell             = hparams[\"cell_type\"],     # \"lstm\" | \"gru\" | \"rnn\"\n",
        "#         dropout          = hparams[\"dropout\"],\n",
        "#         bidirectional    = hparams[\"bidirectional\"],\n",
        "#         lr               = hparams[\"learning_rate\"],\n",
        "#         optim_name       = hparams[\"optim\"],         # \"adam\" | \"nadam\"\n",
        "#         tf_ratio         = hparams[\"teacher_forcing\"]\n",
        "#     )\n",
        "\n",
        "#     # 3) Trainer\n",
        "#     ckpt = ModelCheckpoint(monitor=\"val_loss\", save_top_k=1, mode=\"min\")\n",
        "#     trainer = Trainer(\n",
        "#         max_epochs = hparams[\"epochs\"],\n",
        "#         callbacks  = [ckpt],\n",
        "#         accelerator= \"auto\",\n",
        "#         devices    = 1\n",
        "#     )\n",
        "\n",
        "#     # 4) Fit + Test\n",
        "#     trainer.fit(model, dm)\n",
        "#     trainer.test(model, dm)            # uses best checkpoint by default\n",
        " #################################################################################################################\n",
        "\n",
        "\n",
        "  # def configure_optimizers(self):\n",
        "  #     return torch.optim.Adam(self.parameters(), learning_rate=self.hparams.learning_rate)\n",
        "\n",
        "  # def __init__(self, src_vocab, trg_vocab,\n",
        "  #              emb_dim=128, hid_dim=256, n_layers=2,\n",
        "  #              cell=\"lstm\", dropout=0.2, lr=1e-3, tf_ratio=0.5):\n",
        "  #     super().__init__()\n",
        "  #     self.save_hyperparameters()\n",
        "  #     self.encoder  = Encoder(len(src_vocab), emb_dim, hid_dim, n_layers, cell, dropout)\n",
        "  #     self.decoder  = Decoder(len(trg_vocab), emb_dim, hid_dim, n_layers, cell, dropout)\n",
        "  #     self.criterion= nn.NLLLoss(ignore_index=trg_vocab[\"<pad>\"])\n",
        "  #     self.pad_idx  = trg_vocab[\"<pad>\"]\n",
        "  #     self.tf_ratio = tf_ratio\n",
        "\n",
        "  # # ---------- forward ----------\n",
        "  # def forward(self, src, trg, teacher_forcing):\n",
        "  #     trg_len, batch = trg.shape\n",
        "  #     vocab_size = len(self.decoder.embedding.weight)\n",
        "  #     outputs = torch.zeros(trg_len, batch, vocab_size, device=src.device)\n",
        "\n",
        "  #     _, hidden = self.encoder(src)\n",
        "  #     inp = trg[0].unsqueeze(0)           # <s>\n",
        "\n",
        "  #     for t in range(1, trg_len):\n",
        "  #         pred, hidden = self.decoder(inp, hidden)\n",
        "  #         outputs[t]   = pred\n",
        "  #         inp = trg[t].unsqueeze(0) if (torch.rand(1) < teacher_forcing) \\\n",
        "  #               else pred.argmax(1).unsqueeze(0)\n",
        "  #     return outputs\n",
        "\n",
        "  # def __init__(self, encoder: Encoder, decoder: Decoder,\n",
        "  #              cell_type: str = \"lstm\", bidirectional: bool = False, device=\"cpu\"):\n",
        "  #     super().__init__()\n",
        "  #     self.encoder, self.decoder = encoder, decoder\n",
        "  #     self.cell_type = cell_type.lower()\n",
        "  #     self.bidirectional = bidirectional\n",
        "  #     self.device = device"
      ],
      "metadata": {
        "id": "QIliADfIAVRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Function and Sweeps**"
      ],
      "metadata": {
        "id": "xLPbqyGMKRCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "def run_training(hparams: dict):\n",
        "    # 1) Data\n",
        "    dm = DakshinaDataModule(batch_size=hparams[\"batch_size\"])\n",
        "    dm.prepare_data(); dm.setup()\n",
        "\n",
        "    # 2) Build encoder & decoder separately\n",
        "    SRC_VOCAB = len(dm.src_vocab)\n",
        "    TRG_VOCAB = len(dm.trg_vocab)\n",
        "\n",
        "    encoder = Encoder(\n",
        "        input_dim    = SRC_VOCAB,\n",
        "        embed_dim= hparams[\"embedding_size\"],\n",
        "        hid_dim   = hparams[\"hidden_size\"],\n",
        "        n_layers   = hparams[\"num_layers\"],\n",
        "        bidirectional= hparams[\"bidirectional\"],\n",
        "        cell_type    = hparams[\"cell_type\"],\n",
        "        dropout           = hparams[\"dropout\"],\n",
        "    )\n",
        "\n",
        "    decoder = Decoder(\n",
        "        trg_vocab=dm.trg_vocab,\n",
        "        output_dim   = TRG_VOCAB,\n",
        "        embed_dim= hparams[\"embedding_size\"],\n",
        "        hid_dim   = hparams[\"hidden_size\"],\n",
        "        n_layers   = hparams[\"num_layers\"],\n",
        "        bidirectional= False,\n",
        "        cell_type    = hparams[\"cell_type\"],\n",
        "        dropout           = hparams[\"dropout\"],\n",
        "    )\n",
        "\n",
        "    model = Seq2SeqLightning(\n",
        "        encoder       = encoder,\n",
        "        decoder       = decoder,\n",
        "        cell_type     = hparams[\"cell_type\"],\n",
        "        bidirectional = hparams[\"bidirectional\"],\n",
        "        device        = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        learning_rate   = hparams[\"learning_rate\"],\n",
        "        optim_name    = hparams[\"optim\"],\n",
        "        tf_ratio      = hparams[\"teacher_forcing\"],\n",
        "    )\n",
        "\n",
        "    ckpt = ModelCheckpoint(monitor=\"val_loss\", save_top_k=1, mode=\"min\")\n",
        "    run_name = (\n",
        "    f\"e_{hparams['epochs']}_lr_{hparams['learning_rate']}_\"\n",
        "    f\"wd_{hparams.get('weight_decay', 0)}_o_{hparams['optim']}_\"\n",
        "    f\"bs_{hparams['batch_size']}_ac_{hparams.get('activation_type', 'na')}_\"\n",
        "    f\"los_{hparams.get('loss_type', 'ce')}\"\n",
        "    )\n",
        "\n",
        "    wandb_logger = WandbLogger(\n",
        "        project=\"DA6401_Assignment_3\",\n",
        "        # name=(f\"e_{hparams['epochs']}_lr_{hparams['learning_rate']}_\"\n",
        "        #     f\"wd_{hparams.get('weight_decay', 0)}_o_{hparams['optim']}_\"\n",
        "        #     f\"bs_{hparams['batch_size']}_ac_{hparams.get('activation_type', 'na')}_\"\n",
        "        #     f\"los_{hparams.get('loss_type', 'ce')}\"),\n",
        "        config=hparams,\n",
        "        log_model=True\n",
        "    )\n",
        "    wandb.run.name = run_name\n",
        "    early_stop = EarlyStopping(\n",
        "    monitor=\"val_acc\",     # you can also monitor \"val_acc\" if preferred\n",
        "    patience=3,             # stop after 3 epochs with no improvement\n",
        "    mode=\"max\",             # minimize validation loss\n",
        "    verbose=True\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        max_epochs = hparams[\"epochs\"],\n",
        "        callbacks  = [ckpt,early_stop],\n",
        "        accelerator= \"auto\",\n",
        "        devices    = 1,\n",
        "        logger     = wandb_logger\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "    # trainer.test(model, dm)          # uses best checkpoint\n",
        "\n",
        "\n",
        "default_hparams = dict(\n",
        "    cell_type       = \"lstm\",\n",
        "    dropout         = 0.2,\n",
        "    embedding_size  = 128,\n",
        "    num_layers      = 2,\n",
        "    batch_size      = 128,\n",
        "    hidden_size     = 256,\n",
        "    bidirectional   = False,\n",
        "    learning_rate   = 1e-3,\n",
        "    epochs          = 10,\n",
        "    optim           = \"adam\",\n",
        "    teacher_forcing = 0.5\n",
        ")\n",
        "\n",
        "# run_training(default_hparams)\n",
        "\n"
      ],
      "metadata": {
        "id": "CDr0__xoAJhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb, yaml, json\n",
        "wandb.login(key=\"41a2853ea088e37bd0d456e78102e82edb455afc\")\n",
        "\n",
        "# sweep_config = {\n",
        "#     \"method\": \"bayes\",\n",
        "#     \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
        "#     \"parameters\": {\n",
        "#         \"batch_size\": {\"values\": [32, 64, 128]},\n",
        "#         \"emb_dim\":    {\"values\": [32,64, 128, 256]},\n",
        "#         \"hid_dim\":    {\"values\": [128, 256, 512]},\n",
        "#         \"n_layers\":   {\"values\": [1, 2, 3]},\n",
        "#         \"cell\":       {\"values\": [\"lstm\", \"gru\",\"rnn\"]},\n",
        "#         \"dropout\":    {\"values\": [0.2, 0.3]},\n",
        "#         \"lr\":         {\"values\": [1e-3, 5e-4]},\n",
        "#         \"tf_ratio\":   {\"values\": [0.2, 0.5]},\n",
        "#         \"epochs\":     {\"value\": [10,13,15]}\n",
        "#     }\n",
        "# }\n",
        "\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",           # or \"random\", \"grid\", …\n",
        "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"cell_type\":      {\"values\": [\"lstm\", \"gru\", \"rnn\"]},\n",
        "        \"dropout\":        {\"values\": [0.0, 0.1, 0.2, 0.5]},\n",
        "        \"embedding_size\": {\"values\": [64, 128, 256, 512]},\n",
        "        \"num_layers\":     {\"values\": [2, 3, 4]},\n",
        "        \"batch_size\":     {\"values\": [32, 64, 128]},\n",
        "        \"hidden_size\":    {\"values\": [128, 256, 512]},\n",
        "        \"bidirectional\":  {\"values\": [True, False]},\n",
        "        \"learning_rate\":  {\"values\": [1e-3, 2e-3, 1e-4, 2e-4]},\n",
        "        \"epochs\":         {\"values\": [7, 10, 13]},\n",
        "        \"optim\":          {\"values\": [\"adam\", \"nadam\"]},\n",
        "        \"teacher_forcing\":{\"values\": [0.2, 0.5, 0.7]},\n",
        "    },\n",
        "}\n",
        "\n",
        "def sweep_train():\n",
        "    with wandb.init() as run:\n",
        "        cfg = dict(run.config)\n",
        "        run_training(cfg)\n",
        "\n",
        "# Uncomment to launch\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assignment_3\",entity=\"cs24m024-iit-madras\")\n",
        "print(sweep_id)\n",
        "wandb.agent(sweep_id, function=sweep_train, count=75)\n"
      ],
      "metadata": {
        "id": "XZYYkRlfAegd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Mechanism**"
      ],
      "metadata": {
        "id": "0dltpHwie4eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DotAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Luong (general=dot) attention.\n",
        "    Scores = h_tᵀ · H_enc  → softmax over src-time\n",
        "    \"\"\"\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.scale = 1.0 / (hid_dim ** 0.5)\n",
        "\n",
        "    def forward(self, dec_hidden, enc_outputs, src_mask=None):\n",
        "        # dec_hidden:  [1,  B, H]\n",
        "        # enc_outputs: [Tsrc, B, H]\n",
        "        scores = torch.einsum('lbh,tbh->lbt', dec_hidden, enc_outputs) * self.scale\n",
        "        if src_mask is not None:\n",
        "            scores = scores.masked_fill(src_mask.T.unsqueeze(0) == 0, -1e9)\n",
        "        attn_w = F.softmax(scores, dim=2)          # over Tsrc\n",
        "        ctx = torch.einsum('lbt,tbh->lbh', attn_w, enc_outputs)\n",
        "        return ctx, attn_w.squeeze(0)              # ctx:[1,B,H], attn_w:[B,Tsrc]\n"
      ],
      "metadata": {
        "id": "c97iO4SQehzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, trg_vocab, output_dim, embed_dim,\n",
        "                 hid_dim, n_layers=1, cell_type=\"lstm\", dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
        "        self.rnn = nn.LSTM(embed_dim + hid_dim, hid_dim, n_layers)\n",
        "        self.attn = DotAttention(hid_dim)\n",
        "        self.fc_out = nn.Linear(hid_dim*2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inp, hidden, enc_out, src_mask=None):\n",
        "        emb = self.dropout(self.embedding(inp))           # [1,B,E]\n",
        "        ctx, attn_w = self.attn(hidden[0] if isinstance(hidden, tuple) else hidden,\n",
        "                                enc_out, src_mask)\n",
        "        rnn_in = torch.cat([emb, ctx], dim=2)\n",
        "        rnn_out, hidden = self.rnn(rnn_in, hidden)\n",
        "        logits = self.fc_out(torch.cat([rnn_out.squeeze(0), ctx.squeeze(0)], dim=1))\n",
        "        return F.log_softmax(logits, dim=1), hidden, attn_w\n"
      ],
      "metadata": {
        "id": "sMDPZnb5elVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqAttn(pl.LightningModule):\n",
        "    # init identical to before, but decoder is AttnDecoder\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder: Encoder,\n",
        "        decoder: Decoder,\n",
        "        cell_type: str = \"lstm\",\n",
        "        bidirectional: bool = False,\n",
        "        device: str = \"cpu\",\n",
        "        learning_rate: float = 1e-3,\n",
        "        optim_name: str = \"adam\",\n",
        "        tf_ratio: float = 0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optim_name = optim_name.lower()\n",
        "        self.tf_ratio = tf_ratio\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index=decoder.trg_vocab[\"<pad>\"])\n",
        "        self.pad_idx = decoder.trg_vocab[\"<pad>\"]\n",
        "        # self.device = device\n",
        "\n",
        "    def _merge_bidir(self, h):\n",
        "        \"\"\"Average the fwd & bwd hidden states so that\n",
        "           [layers*dir, batch, hid] → [layers, batch, hid]\"\"\"\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type == \"lstm\":\n",
        "                # h is tuple(hidden, cell)\n",
        "                hidden = (h[0].view(self.decoder.rnn.num_layers, 2, -1, h[0].size(-1)).mean(1),\n",
        "                          h[1].view(self.decoder.rnn.num_layers, 2, -1, h[1].size(-1)).mean(1))\n",
        "            else:\n",
        "                hidden = h.view(self.decoder.rnn.num_layers, 2, -1, h.size(-1)).mean(1)\n",
        "        else:\n",
        "            hidden = h\n",
        "        return hidden\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch, trg_len = src.size(1), trg.size(0)\n",
        "        vocab = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(trg_len, batch, vocab, device=src.device)\n",
        "        attn_maps = []\n",
        "\n",
        "        enc_out, enc_hidden = self.encoder(src)\n",
        "        hidden = self._merge_bidir(enc_hidden)\n",
        "        dec_inp = trg[0].unsqueeze(0)\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            dec_out, hidden, attn_w = self.decoder(dec_inp, hidden, enc_out)\n",
        "            outputs[t] = dec_out\n",
        "            attn_maps.append(attn_w.detach().cpu())\n",
        "            teacher = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            dec_inp = trg[t].unsqueeze(0) if teacher else dec_out.argmax(1).unsqueeze(0)\n",
        "\n",
        "        return outputs, torch.stack(attn_maps)  # attn: [T-1,B,SrcT]\n",
        "\n",
        "    def _step(self, batch, stage):\n",
        "        src, trg, _, _ = batch\n",
        "        src, trg = src.permute(1,0), trg.permute(1,0)\n",
        "        logits, _ = self(src, trg, self.tf_ratio if stage==\"train\" else 0.0)\n",
        "        loss = self.criterion(logits[1:].reshape(-1, logits.shape[2]),\n",
        "                              trg[1:].reshape(-1))\n",
        "        acc  = self._accuracy(logits[1:].reshape(-1, logits.shape[2]),\n",
        "                              trg[1:].reshape(-1))\n",
        "        self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
        "        self.log(f\"{stage}_acc\",  acc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    # ---------- lightning hooks ----------\n",
        "    def training_step(self, batch, _):   return self._step(batch, \"train\")\n",
        "    def validation_step(self, batch, _): self._step(batch, \"val\")\n",
        "    def test_step(self, batch, _):       self._step(batch, \"test\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        learning_rate  = self.learning_rate\n",
        "        opt = self.optim_name.lower()          # \"adam\" | \"nadam\"\n",
        "\n",
        "        if opt == \"adam\":\n",
        "            optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        elif opt == \"nadam\":\n",
        "            optimizer = torch.optim.NAdam(self.parameters(), lr=learning_rate)\n",
        "        else:                                     # fallback / safety\n",
        "            raise ValueError(f\"Unknown optimizer '{opt}'\")\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    # ---------- helpers ----------\n",
        "    def _accuracy(self, logits, trg):\n",
        "        # logits, trg both exclude <s>\n",
        "        pred = logits.argmax(1)\n",
        "        correct = (pred == trg) & (trg != self.pad_idx)\n",
        "        return correct.float().sum()/ (trg != self.pad_idx).float().sum()\n"
      ],
      "metadata": {
        "id": "9RcfPsXeen_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Function and Sweeps**"
      ],
      "metadata": {
        "id": "PLmsnk8jKX3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "def run_training_attn(hp):\n",
        "    dm = DakshinaDataModule(batch_size=hp[\"batch_size\"]); dm.prepare_data(); dm.setup()\n",
        "    enc = Encoder(len(dm.src_vocab), hp[\"embedding_size\"],\n",
        "                  hp[\"hidden_size\"], 1, hp[\"cell_type\"],\n",
        "                  bidirectional=False, dropout=hp[\"dropout\"])\n",
        "    dec = AttnDecoder(dm.trg_vocab, len(dm.trg_vocab),\n",
        "                      hp[\"embedding_size\"], hp[\"hidden_size\"],\n",
        "                      1, hp[\"cell_type\"], hp[\"dropout\"])\n",
        "\n",
        "    model = Seq2SeqAttn(enc, dec, cell_type=hp[\"cell_type\"],\n",
        "                        learning_rate=hp[\"learning_rate\"],\n",
        "                        optim_name=hp[\"optim\"], tf_ratio=hp[\"teacher_forcing\"])\n",
        "    ckpt = ModelCheckpoint(monitor=\"val_loss\", save_top_k=1, mode=\"min\")\n",
        "    run_name = (\n",
        "    f\"e_{hp['epochs']}_lr_{hp['learning_rate']}_\"\n",
        "    f\"wd_{hp.get('weight_decay', 0)}_o_{hp['optim']}_\"\n",
        "    f\"bs_{hp['batch_size']}_ac_{hp.get('activation_type', 'na')}_\"\n",
        "    f\"los_{hp.get('loss_type', 'ce')}\"\n",
        "    )\n",
        "\n",
        "    wandb_logger = WandbLogger(\n",
        "        project=\"DA6401_Assignment_3\",\n",
        "        config=hp,\n",
        "        log_model=True\n",
        "    )\n",
        "    early_stop = EarlyStopping(\n",
        "    monitor=\"val_acc\",     # you can also monitor \"val_loss\" if preferred\n",
        "    patience=3,             # stop after 3 epochs with no improvement\n",
        "    mode=\"max\",             # minimize validation acc\n",
        "    verbose=True\n",
        "    )\n",
        "    wandb.run.name = run_name\n",
        "    trainer = Trainer(\n",
        "        max_epochs = hp[\"epochs\"],\n",
        "        callbacks  = [ckpt,early_stop],\n",
        "        accelerator= \"auto\",\n",
        "        devices    = 1,\n",
        "        logger     = wandb_logger\n",
        "    )\n",
        "\n",
        "\n",
        "    # trainer.fit(model, dm)\n",
        "    # trainer.test(model, dm)          # uses best checkpoint\n",
        "\n",
        "    trainer.fit(model, dm); trainer.test(model, dm)\n",
        "    return model, dm\n",
        "\n",
        "\n",
        "attn_hparams = default_hparams | {\"num_layers\":1, \"hidden_size\":256, \"learning_rate\":5e-4}\n",
        "best_model, dm = run_training_attn(attn_hparams)\n"
      ],
      "metadata": {
        "id": "tB-Z-_GHeqPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"bayes\",           # or \"random\", \"grid\", …\n",
        "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"cell_type\":      {\"values\": [\"lstm\", \"gru\"]},\n",
        "        \"dropout\":        {\"values\": [0.0, 0.1, 0.2, 0.5]},\n",
        "        \"embedding_size\": {\"values\": [64, 128, 256, 512]},\n",
        "        \"num_layers\":     {\"values\": [2, 3, 4]},\n",
        "        \"batch_size\":     {\"values\": [32, 64, 128]},\n",
        "        \"hidden_size\":    {\"values\": [128, 256, 512]},\n",
        "        \"bidirectional\":  {\"values\": [True, False]},\n",
        "        \"learning_rate\":  {\"values\": [1e-3, 2e-3, 1e-4, 2e-4]},\n",
        "        \"epochs\":         {\"values\": [7, 10, 13]},\n",
        "        \"optim\":          {\"values\": [\"adam\", \"nadam\"]},\n",
        "        \"teacher_forcing\":{\"values\": [0.2, 0.5, 0.7]},\n",
        "    },\n",
        "}\n",
        "\n",
        "def sweep_train():\n",
        "    with wandb.init() as run:\n",
        "        cfg = dict(run.config)\n",
        "        run_training(cfg)\n",
        "\n",
        "# Uncomment to launch\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assignment_3\",entity=\"cs24m024-iit-madras\")\n",
        "print(sweep_id)\n",
        "wandb.agent(sweep_id, function=sweep_train, count=35)"
      ],
      "metadata": {
        "id": "z24wayBuesrq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}