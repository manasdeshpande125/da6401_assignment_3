{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQG0BU2mmMB/UNqPTlxpG1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manasdeshpande125/da6401_assignment_3/blob/main/DLASG3__Word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os, random, numpy as np, pandas as pd\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "EUesgXBTfBfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download dataset and unzip it**"
      ],
      "metadata": {
        "id": "lPZ3CcTFK5aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request, tarfile, pathlib, shutil\n",
        "\n",
        "URL = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "TAR = \"dakshina.tar\"\n",
        "if not pathlib.Path(TAR).exists():\n",
        "    urllib.request.urlretrieve(URL, TAR)\n",
        "    print(\"Downloaded.\")\n",
        "\n",
        "with tarfile.open(TAR) as t:\n",
        "    members = [m for m in t.getmembers() if m.name.startswith(\"dakshina_dataset_v1.0/mr/lexicons/\")]\n",
        "    t.extractall(members=members)\n",
        "DATA_ROOT = pathlib.Path(\"dakshina_dataset_v1.0/mr/lexicons\")\n",
        "print(\"Files:\", os.listdir(DATA_ROOT))"
      ],
      "metadata": {
        "id": "AC1fBT2yg0Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classes for loading and preparing the dataset for word level**"
      ],
      "metadata": {
        "id": "2HkBcLqGK9VR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmZweUXIe8KX"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, file_path, src_lang, trg_lang):\n",
        "        df = pd.read_csv(file_path, sep=\"\\t\", header=None,\n",
        "                         names=[src_lang, trg_lang, \"count\"], dtype=str).dropna()\n",
        "        self.df = df\n",
        "        self.src_lang, self.trg_lang = src_lang, trg_lang\n",
        "\n",
        "        # Create word-level vocabularies\n",
        "        self.src_vocab = {word: i+3 for i, word in enumerate(sorted(set(df[src_lang])))}\n",
        "        self.trg_vocab = {word: i+3 for i, word in enumerate(sorted(set(df[trg_lang])))}\n",
        "\n",
        "        # Add special tokens\n",
        "        for v in (self.src_vocab, self.trg_vocab):\n",
        "            v[\"<pad>\"] = 1\n",
        "            v[\"<unk>\"] = 2\n",
        "            v[\"<s>\"] = 0\n",
        "\n",
        "        self.s_word2idx, self.s_idx2word = self.src_vocab, {i: w for w, i in self.src_vocab.items()}\n",
        "        self.t_word2idx, self.t_idx2word = self.trg_vocab, {i: w for w, i in self.trg_vocab.items()}\n",
        "\n",
        "    def get(self):\n",
        "        return (self.src_vocab, self.trg_vocab,\n",
        "                self.t_word2idx, self.t_idx2word,\n",
        "                self.s_word2idx, self.s_idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, file_path, src_lang, trg_lang,\n",
        "                 src_vocab, trg_vocab, t_word2idx):\n",
        "        df = pd.read_csv(file_path, sep=\"\\t\", header=None,\n",
        "                         names=[src_lang, trg_lang, \"count\"], dtype=str).dropna()\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.src_vocab, self.trg_vocab = src_vocab, trg_vocab\n",
        "        self.t_word2idx = t_word2idx\n",
        "        self.src_lang, self.trg_lang = src_lang, trg_lang\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _encode(self, word, vocab):\n",
        "        return torch.tensor(vocab.get(word, vocab[\"<unk>\"]), dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        src = self._encode(row[self.src_lang], self.src_vocab)\n",
        "        trg = self._encode(row[self.trg_lang], self.trg_vocab)\n",
        "        return src, trg, row[self.src_lang], row[self.trg_lang]"
      ],
      "metadata": {
        "id": "MIIZiJpZfF0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder, Decoder and Seq2Seq Classes for Transliteration**"
      ],
      "metadata": {
        "id": "8iuDPRmQLDiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn, torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim: int, embed_dim: int,\n",
        "                 hid_dim: int, n_layers: int,\n",
        "                 cell_type: str = \"lstm\",\n",
        "                 bidirectional: bool = False,\n",
        "                 dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.hid_dim, self.n_layers = hid_dim, n_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dir = 2 if bidirectional else 1\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "        rnn_cls = {\"rnn\": nn.RNN, \"gru\": nn.GRU, \"lstm\": nn.LSTM}[cell_type.lower()]\n",
        "        self.rnn = rnn_cls(embed_dim, hid_dim, n_layers,\n",
        "                          bidirectional=bidirectional,\n",
        "                          dropout=dropout if n_layers > 1 else 0.0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type.lower()\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src ⇒ [batch]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        embedded = embedded.unsqueeze(0)  # Add sequence dimension\n",
        "        return self.rnn(embedded)  # (output, hidden[, cell])"
      ],
      "metadata": {
        "id": "Xfishy0LfH5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, trg_vocab, output_dim, embed_dim, hid_dim, n_layers,\n",
        "                cell_type: str = \"lstm\", bidirectional: bool = False, dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.trg_vocab = trg_vocab  # store it here for loss\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
        "        rnn_cls = {\"rnn\": nn.RNN, \"gru\": nn.GRU, \"lstm\": nn.LSTM}[cell_type.lower()]\n",
        "        self.rnn = rnn_cls(embed_dim, hid_dim, n_layers,\n",
        "                          dropout=dropout if n_layers > 1 else 0.0)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "    def forward(self, inp, hidden):\n",
        "        # inp ⇒ [batch]\n",
        "        embedded = self.dropout(self.embedding(inp))\n",
        "        embedded = embedded.unsqueeze(0)  # Add sequence dimension\n",
        "        outputs = self.rnn(embedded, hidden)\n",
        "        rnn_out, hidden = outputs if self.cell_type != \"lstm\" else (outputs[0], outputs[1])\n",
        "        logits = self.fc_out(rnn_out.squeeze(0))\n",
        "        return F.log_softmax(logits, dim=1), hidden"
      ],
      "metadata": {
        "id": "Xx0Y8t8KfKBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqLightning(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder: Encoder,\n",
        "        decoder: Decoder,\n",
        "        t_word2idx: dict,\n",
        "        t_idx2word: dict,\n",
        "        cell_type: str = \"lstm\",\n",
        "        bidirectional: bool = False,\n",
        "        device: str = \"cpu\",\n",
        "        learning_rate: float = 1e-3,\n",
        "        optim_name: str = \"adam\",\n",
        "        tf_ratio: float = 0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.t_word2idx = t_word2idx  # Store target word to index mapping\n",
        "        self.t_idx2word = t_idx2word  # Store index to target word mapping\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optim_name = optim_name.lower()\n",
        "        self.tf_ratio = tf_ratio\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index=decoder.trg_vocab[\"<pad>\"])\n",
        "        self.pad_idx = decoder.trg_vocab[\"<pad>\"]\n",
        "        self.predictions = []\n",
        "\n",
        "    def _merge_bidir(self, h):\n",
        "        \"\"\"Average the fwd & bwd hidden states so that\n",
        "           [layers*dir, batch, hid] → [layers, batch, hid]\"\"\"\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type == \"lstm\":\n",
        "                # h is tuple(hidden, cell)\n",
        "                hidden = (h[0].view(self.decoder.rnn.num_layers, 2, -1, h[0].size(-1)).mean(1),\n",
        "                         h[1].view(self.decoder.rnn.num_layers, 2, -1, h[1].size(-1)).mean(1))\n",
        "            else:\n",
        "                hidden = h.view(self.decoder.rnn.num_layers, 2, -1, h.size(-1)).mean(1)\n",
        "        else:\n",
        "            hidden = h\n",
        "        return hidden\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # Single step prediction (since we're doing word-level)\n",
        "        enc_out, enc_hidden = self.encoder(src)\n",
        "        dec_hidden = self._merge_bidir(enc_hidden)\n",
        "\n",
        "        dec_inp = trg  # For word-level, we predict in one step\n",
        "        dec_out, dec_hidden = self.decoder(dec_inp, dec_hidden)\n",
        "\n",
        "        return dec_out.unsqueeze(0)  # Add sequence dimension for compatibility\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        learning_rate = self.learning_rate\n",
        "        opt = self.optim_name.lower()  # \"adam\" | \"nadam\"\n",
        "\n",
        "        if opt == \"adam\":\n",
        "            optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        elif opt == \"nadam\":\n",
        "            optimizer = torch.optim.NAdam(self.parameters(), lr=learning_rate)\n",
        "        else:  # fallback / safety\n",
        "            raise ValueError(f\"Unknown optimizer '{opt}'\")\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def _accuracy(self, logits, trg):\n",
        "        pred = logits.argmax(1)\n",
        "        correct = (pred == trg) & (trg != self.pad_idx)\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def _word_accuracy(self, pred_words, true_words):\n",
        "        correct = sum(1 for p, t in zip(pred_words, true_words) if p == t)\n",
        "        return correct / len(true_words)\n",
        "\n",
        "    def _step(self, batch, stage):\n",
        "        src, trg, src_words, trg_words = batch\n",
        "\n",
        "        logits = self(src, trg, self.tf_ratio if stage==\"train\" else 0.0)\n",
        "        loss = self.criterion(logits.squeeze(0), trg)\n",
        "\n",
        "        # Calculate token-level accuracy\n",
        "        acc = self._accuracy(logits.squeeze(0), trg)\n",
        "\n",
        "        # Calculate word-level accuracy\n",
        "        pred_indices = torch.argmax(logits.squeeze(0), dim=1).tolist()\n",
        "        pred_words = [self.t_idx2word.get(idx, \"<unk>\") for idx in pred_indices]\n",
        "        word_acc = self._word_accuracy(pred_words, trg_words)\n",
        "\n",
        "        self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
        "        self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
        "        self.log(f\"{stage}_word_acc\", word_acc, prog_bar=True)\n",
        "\n",
        "        # Store predictions for validation and test\n",
        "        if stage in [\"val\", \"test\"]:\n",
        "            for s_word, t_word, p_word in zip(src_words, trg_words, pred_words):\n",
        "                self.predictions.append({\n",
        "                    \"input\": s_word,\n",
        "                    \"target\": t_word,\n",
        "                    \"predicted\": p_word\n",
        "                })\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, _): return self._step(batch, \"train\")\n",
        "    def validation_step(self, batch, _): return self._step(batch, \"val\")\n",
        "    def test_step(self, batch, _): return self._step(batch, \"test\")\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Save predictions to CSV after validation epoch\n",
        "        if self.predictions:\n",
        "            df = pd.DataFrame(self.predictions)\n",
        "            # df.to_csv(f\"val_predictions_epoch_{self.current_epoch}.csv\", index=False)\n",
        "            self.predictions = []  # Clear predictions for next epoch\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        # Save final test predictions\n",
        "        if self.predictions:\n",
        "            df = pd.DataFrame(self.predictions)\n",
        "            df.to_csv(\"test_predictions_final.csv\", index=False)"
      ],
      "metadata": {
        "id": "rmndExpafM7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Function and Sweeps**"
      ],
      "metadata": {
        "id": "hEvyiGUuLJJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "def run_training(hparams: dict):\n",
        "    # 1) Data\n",
        "    dm = DakshinaDataModule(batch_size=hparams[\"batch_size\"])\n",
        "    dm.prepare_data(); dm.setup()\n",
        "\n",
        "    # 2) Build encoder & decoder separately\n",
        "    SRC_VOCAB = len(dm.src_vocab)\n",
        "    TRG_VOCAB = len(dm.trg_vocab)\n",
        "\n",
        "    encoder = Encoder(\n",
        "        input_dim=SRC_VOCAB,\n",
        "        embed_dim=hparams[\"embedding_size\"],\n",
        "        hid_dim=hparams[\"hidden_size\"],\n",
        "        n_layers=hparams[\"num_layers\"],\n",
        "        bidirectional=hparams[\"bidirectional\"],\n",
        "        cell_type=hparams[\"cell_type\"],\n",
        "        dropout=hparams[\"dropout\"],\n",
        "    )\n",
        "\n",
        "    decoder = Decoder(\n",
        "        trg_vocab=dm.trg_vocab,\n",
        "        output_dim=TRG_VOCAB,\n",
        "        embed_dim=hparams[\"embedding_size\"],\n",
        "        hid_dim=hparams[\"hidden_size\"],\n",
        "        n_layers=hparams[\"num_layers\"],\n",
        "        bidirectional=False,\n",
        "        cell_type=hparams[\"cell_type\"],\n",
        "        dropout=hparams[\"dropout\"],\n",
        "    )\n",
        "\n",
        "    model = Seq2SeqLightning(\n",
        "        encoder=encoder,\n",
        "        decoder=decoder,\n",
        "        t_word2idx=dm.t_word2idx,  # Pass target word to index mapping\n",
        "        t_idx2word=dm.t_idx2word,  # Pass index to target word mapping\n",
        "        cell_type=hparams[\"cell_type\"],\n",
        "        bidirectional=hparams[\"bidirectional\"],\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        learning_rate=hparams[\"learning_rate\"],\n",
        "        optim_name=hparams[\"optim\"],\n",
        "        tf_ratio=hparams[\"teacher_forcing\"],\n",
        "    )\n",
        "\n",
        "    ckpt = ModelCheckpoint(monitor=\"val_word_acc\", save_top_k=1, mode=\"max\")\n",
        "    run_name = (\n",
        "        f\"word_level_e{hparams['epochs']}_lr{hparams['learning_rate']}_\"\n",
        "        f\"bs{hparams['batch_size']}_emb{hparams['embedding_size']}_\"\n",
        "        f\"hid{hparams['hidden_size']}\"\n",
        "    )\n",
        "\n",
        "    wandb_logger = WandbLogger(\n",
        "        project=\"DA6401_Assignment_3_WordLevel\",\n",
        "        name=run_name,\n",
        "        config=hparams,\n",
        "        log_model=True\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor=\"val_word_acc\",\n",
        "        patience=3,\n",
        "        mode=\"max\",\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        max_epochs=hparams[\"epochs\"],\n",
        "        callbacks=[ckpt, early_stop],\n",
        "        accelerator=\"auto\",\n",
        "        devices=1,\n",
        "        logger=wandb_logger\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "    trainer.test(model, dm)  # Test with best model\n",
        "\n",
        "default_hparams = dict(\n",
        "    cell_type=\"lstm\",\n",
        "    dropout=0.2,\n",
        "    embedding_size=256,\n",
        "    num_layers=2,\n",
        "    batch_size=128,\n",
        "    hidden_size=512,\n",
        "    bidirectional=False,\n",
        "    learning_rate=1e-3,\n",
        "    epochs=20,\n",
        "    optim=\"adam\",\n",
        "    teacher_forcing=0.5\n",
        ")\n",
        "\n",
        "# run_training(default_hparams)"
      ],
      "metadata": {
        "id": "hQqWIWJmfRvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb, yaml, json\n",
        "wandb.login(key=\"41a2853ea088e37bd0d456e78102e82edb455afc\")\n",
        "\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",           # or \"random\", \"grid\", …\n",
        "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"cell_type\":      {\"values\": [\"lstm\", \"gru\", \"rnn\"]},\n",
        "        \"dropout\":        {\"values\": [0.0, 0.1, 0.2, 0.5]},\n",
        "        \"embedding_size\": {\"values\": [64, 128, 256, 512]},\n",
        "        \"num_layers\":     {\"values\": [2, 3, 4]},\n",
        "        \"batch_size\":     {\"values\": [32, 64, 128]},\n",
        "        \"hidden_size\":    {\"values\": [128, 256, 512]},\n",
        "        \"bidirectional\":  {\"values\": [True, False]},\n",
        "        \"learning_rate\":  {\"values\": [1e-3, 2e-3, 1e-4, 2e-4]},\n",
        "        \"epochs\":         {\"values\": [7, 10, 13]},\n",
        "        \"optim\":          {\"values\": [\"adam\", \"nadam\"]},\n",
        "        \"teacher_forcing\":{\"values\": [0.2, 0.5, 0.7]},\n",
        "    },\n",
        "}\n",
        "\n",
        "def sweep_train():\n",
        "    with wandb.init() as run:\n",
        "        cfg = dict(run.config)\n",
        "        run_training(cfg)\n",
        "\n",
        "# Uncomment to launch\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assignment_3\",entity=\"cs24m024-iit-madras\")\n",
        "print(sweep_id)\n",
        "wandb.agent(sweep_id, function=sweep_train, count=75)\n"
      ],
      "metadata": {
        "id": "jjvmPgz-fYG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Listing down Predictions**"
      ],
      "metadata": {
        "id": "qIjNjS6mLjn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# Mapping indices to tokens\n",
        "index_to_char = {i: c for c, i in target_tokenizer.word_index.items()}\n",
        "index_to_char[0] = ''\n",
        "\n",
        "# Decode predicted sequences\n",
        "def decode_seq(seq):\n",
        "    return ''.join(index_to_char.get(idx, '') for idx in seq if idx != 0 and index_to_char.get(idx, '') != '\\n')\n",
        "\n",
        "# Directory for storing predictions\n",
        "os.makedirs(\"predictions_vanilla\", exist_ok=True)\n",
        "\n",
        "# Get model predictions\n",
        "preds = best_model.predict([test_encoder_input, test_decoder_input], verbose=1)\n",
        "pred_indices = np.argmax(preds, axis=-1)\n",
        "\n",
        "# Decode predictions and references\n",
        "decoded_preds = [decode_seq(seq) for seq in pred_indices]\n",
        "decoded_refs = [ref.replace(' </s>', '') for ref in test_deva_out]\n",
        "\n",
        "# Save predictions to .txt\n",
        "with open(\"predictions_vanilla/test_predictions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for inp, pred, ref in zip(test_lat, decoded_preds, decoded_refs):\n",
        "        f.write(f\"{inp}\\t{pred}\\t{ref}\\n\")\n",
        "\n",
        "# Save predictions to .csv\n",
        "with open(\"predictions_vanilla/test_predictions.csv\", \"w\", encoding=\"utf-8\", newline='') as f_csv:\n",
        "    writer = csv.writer(f_csv)\n",
        "    writer.writerow([\"Input\", \"Predicted\", \"Reference\"])\n",
        "    writer.writerows(zip(test_lat, decoded_preds, decoded_refs))\n",
        "\n",
        "# Print top 10 predictions\n",
        "for i, (inp, pred, ref) in enumerate(zip(test_lat, decoded_preds, decoded_refs)[:10], 1):\n",
        "    print(f\"{i}. Input: {inp}\\n   Predicted: {pred}\\n   Reference: {ref}\\n\")\n"
      ],
      "metadata": {
        "id": "t5ZWHP-ALirI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Classes**"
      ],
      "metadata": {
        "id": "1QQj61YJLN6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        hidden = hidden.repeat(src_len, 1, 1)  # [src_len, batch, hid_dim]\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)  # [src_len, batch]\n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        return F.softmax(attention, dim=0)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "        self.rnn = nn.LSTM(embed_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        packed = pack_padded_sequence(embedded, src_len, enforce_sorted=False)\n",
        "        outputs, (hidden, cell) = self.rnn(packed)\n",
        "        outputs, _ = pad_packed_sequence(outputs)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "        cell = torch.tanh(self.fc(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1)))\n",
        "\n",
        "        return outputs, hidden.unsqueeze(0), cell.unsqueeze(0)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, embed_dim, hid_dim, n_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
        "        self.rnn = nn.LSTM(embed_dim + hid_dim * 2, hid_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim * 3 + embed_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs, mask):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        a = self.attention(hidden[-1], encoder_outputs, mask)\n",
        "        a = a.permute(1, 0).unsqueeze(1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a, encoder_outputs).permute(1, 0, 2)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "\n",
        "        prediction = self.fc_out(torch.cat(\n",
        "            (output.squeeze(0), weighted.squeeze(0), embedded.squeeze(0)), dim=1))\n",
        "\n",
        "        return prediction, hidden, cell"
      ],
      "metadata": {
        "id": "SmwtgyH6gIDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Attention(nn.Module):\n",
        "#     def __init__(self, hidden_size):\n",
        "#         super().__init__()\n",
        "#         self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
        "#         self.v = nn.Linear(hidden_size, 1, bias=False)\n",
        "\n",
        "#     def forward(self, hidden, encoder_outputs, mask):\n",
        "#         # hidden = [1, batch, hid_dim]\n",
        "#         # encoder_outputs = [src_len, batch, hid_dim]\n",
        "\n",
        "#         src_len = encoder_outputs.shape[0]\n",
        "\n",
        "#         # Repeat decoder hidden state src_len times\n",
        "#         hidden = hidden.repeat(src_len, 1, 1)  # [src_len, batch, hid_dim]\n",
        "\n",
        "#         energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "#         attention = self.v(energy).squeeze(2)  # [src_len, batch]\n",
        "\n",
        "#         attention = attention.masked_fill(mask == 0, -1e10)\n",
        "#         return F.softmax(attention, dim=0)  # [src_len, batch]\n",
        "\n",
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self, input_dim, embed_dim, hid_dim, n_layers, dropout):\n",
        "#         super().__init__()\n",
        "#         self.hid_dim = hid_dim\n",
        "#         self.n_layers = n_layers\n",
        "#         self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "#         self.rnn = nn.LSTM(embed_dim, hid_dim, n_layers, dropout=dropout, bidirectional=True)\n",
        "#         self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "#     def forward(self, src, src_len):\n",
        "#         # src = [src_len, batch]\n",
        "#         embedded = self.dropout(self.embedding(src))  # [src_len, batch, embed_dim]\n",
        "\n",
        "#         packed = pack_padded_sequence(embedded, src_len, enforce_sorted=False)\n",
        "#         outputs, (hidden, cell) = self.rnn(packed)\n",
        "#         outputs, _ = pad_packed_sequence(outputs)  # [src_len, batch, hid_dim * 2]\n",
        "\n",
        "#         # Combine bidirectional outputs\n",
        "#         hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "#         cell = torch.tanh(self.fc(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1)))\n",
        "\n",
        "#         return outputs, hidden.unsqueeze(0), cell.unsqueeze(0)\n",
        "\n",
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, output_dim, embed_dim, hid_dim, n_layers, dropout, attention):\n",
        "#         super().__init__()\n",
        "#         self.output_dim = output_dim\n",
        "#         self.hid_dim = hid_dim\n",
        "#         self.attention = attention\n",
        "#         self.embedding = nn.Embedding(output_dim, embed_dim)\n",
        "#         self.rnn = nn.LSTM(embed_dim + hid_dim * 2, hid_dim, n_layers, dropout=dropout)\n",
        "#         self.fc_out = nn.Linear(hid_dim * 3 + embed_dim, output_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "#     def forward(self, input, hidden, cell, encoder_outputs, mask):\n",
        "#         # input = [batch]\n",
        "#         # hidden = [n_layers, batch, hid_dim]\n",
        "#         # cell = [n_layers, batch, hid_dim]\n",
        "\n",
        "#         input = input.unsqueeze(0)  # [1, batch]\n",
        "#         embedded = self.dropout(self.embedding(input))  # [1, batch, embed_dim]\n",
        "\n",
        "#         a = self.attention(hidden[-1], encoder_outputs, mask)  # [src_len, batch]\n",
        "#         a = a.permute(1, 0).unsqueeze(1)  # [batch, 1, src_len]\n",
        "\n",
        "#         encoder_outputs = encoder_outputs.permute(1, 0, 2)  # [batch, src_len, hid_dim*2]\n",
        "#         weighted = torch.bmm(a, encoder_outputs)  # [batch, 1, hid_dim*2]\n",
        "#         weighted = weighted.permute(1, 0, 2)  # [1, batch, hid_dim*2]\n",
        "\n",
        "#         rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "#         output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "\n",
        "#         embedded = embedded.squeeze(0)\n",
        "#         output = output.squeeze(0)\n",
        "#         weighted = weighted.squeeze(0)\n",
        "\n",
        "#         prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
        "\n",
        "#         return prediction, hidden, cell\n",
        "\n",
        "class Seq2SeqLightning(pl.LightningModule):\n",
        "    def __init__(self, encoder, decoder, src_vocab, trg_vocab, learning_rate=1e-3):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index=trg_vocab[\"<pad>\"])\n",
        "        self.predictions = []\n",
        "\n",
        "        # Save hyperparameters for logging\n",
        "        self.save_hyperparameters(ignore=['encoder', 'decoder', 'src_vocab', 'trg_vocab'])\n",
        "\n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_vocab[\"<pad>\"]).permute(1, 0)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src, src_len)\n",
        "        input = trg[0,:]  # First input is <sos>\n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs, mask)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _accuracy(self, logits, trg):\n",
        "        pred = logits.argmax(2)\n",
        "        correct = (pred == trg) & (trg != self.trg_vocab[\"<pad>\"])\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def _word_accuracy(self, pred_words, true_words):\n",
        "        correct = sum(1 for p, t in zip(pred_words, true_words) if p == t)\n",
        "        return correct / len(true_words)\n",
        "\n",
        "    def _step(self, batch, stage):\n",
        "        src, trg, src_len, trg_len, src_words, trg_words = batch\n",
        "        output = self(src, src_len, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "\n",
        "        loss = self.criterion(output, trg)\n",
        "        acc = self._accuracy(output.view(-1, output_dim), trg)\n",
        "\n",
        "        # Calculate word-level accuracy\n",
        "        pred_indices = output.view(-1, output_dim).argmax(1)\n",
        "        pred_words = [self.trg_vocab.get(idx.item(), \"<unk>\") for idx in pred_indices]\n",
        "        word_acc = self._word_accuracy(pred_words, trg_words)\n",
        "\n",
        "        self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
        "        self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
        "        self.log(f\"{stage}_word_acc\", word_acc, prog_bar=True)\n",
        "\n",
        "        if stage in [\"val\", \"test\"]:\n",
        "            for s_word, t_word, p_word in zip(src_words, trg_words, pred_words):\n",
        "                self.predictions.append({\n",
        "                    \"input\": s_word,\n",
        "                    \"target\": t_word,\n",
        "                    \"predicted\": p_word\n",
        "                })\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._step(batch, \"train\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self._step(batch, \"val\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self._step(batch, \"test\")\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        if self.predictions:\n",
        "            df = pd.DataFrame(self.predictions)\n",
        "            df.to_csv(f\"val_predictions_epoch_{self.current_epoch}.csv\", index=False)\n",
        "            self.predictions = []\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        if self.predictions:\n",
        "            df = pd.DataFrame(self.predictions)\n",
        "            df.to_csv(\"test_predictions_final.csv\", index=False)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
      ],
      "metadata": {
        "id": "cuO_sE5Vfcxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Function and Sample Run**"
      ],
      "metadata": {
        "id": "UQrLXqSFLWSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "\n",
        "# Initialize data module\n",
        "dm = DakshinaDataModule(batch_size=BATCH_SIZE)\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "\n",
        "# Get vocabulary sizes from the data module\n",
        "SRC_VOCAB_SIZE = len(dm.src_vocab)\n",
        "TRG_VOCAB_SIZE = len(dm.trg_vocab)\n",
        "\n",
        "# Initialize model components\n",
        "attention = Attention(hidden_size=HID_DIM)\n",
        "encoder = Encoder(\n",
        "    input_dim=SRC_VOCAB_SIZE,\n",
        "    embed_dim=EMB_DIM,\n",
        "    hid_dim=HID_DIM,\n",
        "    n_layers=N_LAYERS,\n",
        "    dropout=DROPOUT\n",
        ")\n",
        "decoder = Decoder(\n",
        "    output_dim=TRG_VOCAB_SIZE,\n",
        "    embed_dim=EMB_DIM,\n",
        "    hid_dim=HID_DIM,\n",
        "    n_layers=N_LAYERS,\n",
        "    dropout=DROPOUT,\n",
        "    attention=attention\n",
        ")\n",
        "\n",
        "# Initialize the complete model\n",
        "model = Seq2SeqLightning(\n",
        "    encoder=encoder,\n",
        "    decoder=decoder,\n",
        "    src_vocab=dm.src_vocab,\n",
        "    trg_vocab=dm.trg_vocab,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE\n",
        ")\n",
        "\n",
        "# Training callbacks\n",
        "ckpt = ModelCheckpoint(\n",
        "    monitor=\"val_word_acc\",\n",
        "    mode=\"max\",\n",
        "    save_top_k=1,\n",
        "    filename=\"best-model\"\n",
        ")\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_word_acc\",\n",
        "    patience=3,\n",
        "    mode=\"max\"\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    max_epochs=EPOCHS,\n",
        "    callbacks=[ckpt, early_stop],\n",
        "    accelerator=\"auto\",\n",
        "    devices=1,\n",
        "    logger=WandbLogger(project=\"DA6401_Assignment_3\")\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.fit(model, dm)\n",
        "trainer.test(model, dm)"
      ],
      "metadata": {
        "id": "wGzGVjerf6i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Best Model**"
      ],
      "metadata": {
        "id": "rVOS1oeoLa3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the best model checkpoint saved during training\n",
        "best_model_path = \"lightning_logs/version_0/checkpoints/best-model.ckpt\"\n",
        "\n",
        "# Load the best model\n",
        "best_model = Seq2SeqLightning.load_from_checkpoint(\n",
        "    checkpoint_path=best_model_path,\n",
        "    encoder=encoder,\n",
        "    decoder=decoder,\n",
        "    src_vocab=dm.src_vocab,\n",
        "    trg_vocab=dm.trg_vocab,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE\n",
        ")"
      ],
      "metadata": {
        "id": "tf75aYHcj7Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_with_attention(model, input_tensor, target_tokenizer, max_len=50, start_token='<s>', end_token='</s>'):\n",
        "    \"\"\"\n",
        "    Performs greedy decoding with attention, returning predicted string and attention weights.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch Lightning model\n",
        "        input_tensor: Input tensor of shape (1, seq_len) for a single example\n",
        "        target_tokenizer: tokenizer with word_index and index_word\n",
        "        max_len: Maximum length of decoded output\n",
        "        start_token: Start-of-sequence token\n",
        "        end_token: End-of-sequence token\n",
        "\n",
        "    Returns:\n",
        "        decoded_text: Final decoded string\n",
        "        attention_weights_all: List of attention weights for each decoding timestep\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    index_to_token = {v: k for k, v in target_tokenizer.word_index.items()}\n",
        "    index_to_token[0] = ''\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_tensor = input_tensor.to(model.device)\n",
        "        encoder_outputs, hidden, cell = model.encoder(input_tensor)\n",
        "        decoder_input = torch.tensor([[target_tokenizer.word_index[start_token]]], device=model.device)\n",
        "\n",
        "        decoded_tokens = []\n",
        "        attention_weights_all = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            embedded = model.decoder.embedding(decoder_input)  # (1, 1, emb_dim)\n",
        "            context_vector, attn_weights = model.attention(encoder_outputs, hidden)  # (1, enc_dim), (1, seq_len)\n",
        "            rnn_input = torch.cat((embedded, context_vector.unsqueeze(1)), dim=2)\n",
        "            output, (hidden, cell) = model.decoder.lstm(rnn_input, (hidden.unsqueeze(0), cell.unsqueeze(0)))\n",
        "            logits = model.decoder.out(output.squeeze(1))  # (1, vocab_size)\n",
        "\n",
        "            predicted_id = torch.argmax(logits, dim=1).item()\n",
        "            decoded_tokens.append(predicted_id)\n",
        "            attention_weights_all.append(attn_weights.squeeze(0).cpu().numpy())  # shape: (seq_len,)\n",
        "\n",
        "            if predicted_id == target_tokenizer.word_index.get(end_token):\n",
        "                break\n",
        "\n",
        "            decoder_input = torch.tensor([[predicted_id]], device=model.device)\n",
        "\n",
        "        decoded_text = ''.join([index_to_token.get(idx, '') for idx in decoded_tokens])\n",
        "        return decoded_text, attention_weights_all\n"
      ],
      "metadata": {
        "id": "gZXJCnzBmezN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Table for sample predictions**"
      ],
      "metadata": {
        "id": "vJIlbZSfLzon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_colored_prediction_table(samples, save_path=\"predictions/colored_table.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    tbl = Table(ax, bbox=[0, 0, 1, 1])\n",
        "    col_widths = [0.3, 0.4, 0.3]\n",
        "    headers = [\"Input Word\", \"Predicted Word\", \"Target Word\"]\n",
        "\n",
        "    # Add headers\n",
        "    for col_idx, title in enumerate(headers):\n",
        "        tbl.add_cell(0, col_idx, col_widths[col_idx], 0.05, text=title, loc='center', facecolor='lightgrey')\n",
        "\n",
        "    # Add prediction rows\n",
        "    for row_idx, (inp, pred, ref) in enumerate(samples, start=1):\n",
        "        color = 'lightgreen' if pred == ref else 'lightcoral'\n",
        "        tbl.add_cell(row_idx, 0, col_widths[0], 0.05, text=inp, loc='center')\n",
        "        tbl.add_cell(row_idx, 1, col_widths[1], 0.05, text=pred, loc='center', facecolor=color)\n",
        "        tbl.add_cell(row_idx, 2, col_widths[2], 0.05, text=ref, loc='center')\n",
        "\n",
        "    tbl.set_fontsize(12)\n",
        "    tbl.scale(1, 1.5)\n",
        "    ax.add_table(tbl)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "# Prepare sample data for the table\n",
        "sample_data = list(zip(test_lat[:20], decoded_preds[:20], decoded_refs[:20]))\n",
        "plot_colored_prediction_table(sample_data)\n",
        "\n",
        "# Log as image to WandB\n",
        "wandb.log({\"Prediction Table Image\": wandb.Image(\"predictions/colored_table.png\")})\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "OQTvEWYhklc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model to create heatmaps**"
      ],
      "metadata": {
        "id": "Zzrys-aDL7S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile the attention-based sequence-to-sequence model\n",
        "attention_model = build_attention_seq2seq_model(\n",
        "    vocab_size_input=VOCAB_SIZE_INPUT,\n",
        "    vocab_size_target=VOCAB_SIZE_TARGET,\n",
        "    embedding_dim=256,\n",
        "    hidden_dim=256,\n",
        "    dropout_rate=0.0\n",
        ")\n",
        "\n",
        "attention_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model on training data with validation set\n",
        "attention_model.fit(\n",
        "    [train_encoder_input, train_decoder_input],\n",
        "    train_target_output,\n",
        "    validation_data=([val_encoder_input, val_decoder_input], val_target_output),\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "2t1nxvk4lJ1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Noting down the predictions with attention**"
      ],
      "metadata": {
        "id": "-9AkuD_gMCWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Ensure prediction directory exists\n",
        "os.makedirs(\"predictions_attentions\", exist_ok=True)\n",
        "\n",
        "# Generate predictions using the best model\n",
        "predictions = best_model.predict([test_encoder_input, test_decoder_input])\n",
        "predicted_token_ids = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# Map token indices to characters\n",
        "index_to_token = {i: token for token, i in target_tokenizer.word_index.items()}\n",
        "index_to_token[0] = ''\n",
        "\n",
        "def decode_prediction(sequence):\n",
        "    tokens = []\n",
        "    for idx in sequence:\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        char = index_to_token.get(idx, '')\n",
        "        if char == '\\n':  # stop at end-of-sequence token\n",
        "            break\n",
        "        tokens.append(char)\n",
        "    return ''.join(tokens)\n",
        "\n",
        "# Decode all predicted and target sequences\n",
        "decoded_predictions = [decode_prediction(seq) for seq in predicted_token_ids]\n",
        "decoded_references = [ref.replace(' </s>', '') for ref in test_deva_out]\n",
        "\n",
        "# Write predictions to CSV\n",
        "with open(\"predictions_attentions/test_predictions.csv\", \"w\", encoding=\"utf-8\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Input (Latin)\", \"Predicted (Devanagari)\", \"Actual (Devanagari)\"])\n",
        "    for lat_input, prediction, reference in zip(test_lat, decoded_predictions, decoded_references):\n",
        "        writer.writerow([lat_input, prediction, reference])\n"
      ],
      "metadata": {
        "id": "KJnoARN6lNjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some plotting functions**"
      ],
      "metadata": {
        "id": "5h6XhOKZMPz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_9_grid():\n",
        "    plt.figure(figsize=(20, 16))\n",
        "    sns.set(style=\"white\")  # clean style\n",
        "\n",
        "    for i in range(9):\n",
        "        input_text = test_lat[i]\n",
        "        input_seq = test_encoder_input[i:i+1]\n",
        "        output_text, attn_weights = decode_with_attention(input_seq)\n",
        "        attn_matrix = np.stack(attn_weights)  # shape: (dec_len, enc_len)\n",
        "\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        sns.heatmap(\n",
        "            attn_matrix,\n",
        "            xticklabels=list(input_text),\n",
        "            yticklabels=list(output_text),\n",
        "            cmap='YlGnBu',       # aesthetic colormap\n",
        "            cbar=False,\n",
        "            linewidths=0.0,      # cleaner grid\n",
        "            square=True,\n",
        "            annot=False          # optionally: annot=True for numeric values\n",
        "        )\n",
        "\n",
        "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=10, ha='right')\n",
        "        ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=10)\n",
        "        ax.set_xlabel(\"Input (Latin)\", fontsize=12)\n",
        "        ax.set_ylabel(\"Output (Marathi)\", fontsize=12)\n",
        "        ax.set_title(f\"Input: {input_text}\", fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(\"Attention Heatmaps (Latin → Marathi)\", fontsize=18, fontweight='bold', y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_9_grid()\n"
      ],
      "metadata": {
        "id": "NH2K32zYl2XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.makedirs(\"attention_heatmaps\", exist_ok=True)\n",
        "\n",
        "sns.set(style=\"white\")  # clean and minimal theme\n",
        "\n",
        "for i in range(10):\n",
        "    input_text = test_lat[i]\n",
        "    input_seq = test_encoder_input[i:i+1]\n",
        "    output_text, attn_weights = decode_with_attention(input_seq)\n",
        "    attn_matrix = np.stack(attn_weights)\n",
        "\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    ax = sns.heatmap(\n",
        "        attn_matrix,\n",
        "        xticklabels=list(input_text),\n",
        "        yticklabels=list(output_text),\n",
        "        cmap='rocket',         # or try 'YlGnBu', 'viridis', 'coolwarm'\n",
        "        linewidths=0,\n",
        "        cbar=False,\n",
        "        square=True\n",
        "    )\n",
        "\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=10)\n",
        "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=10)\n",
        "\n",
        "    plt.xlabel(\"Input (Latin)\", fontsize=12)\n",
        "    plt.ylabel(\"Output (Marathi)\", fontsize=12)\n",
        "    plt.title(f\"Sample {i+1}: {input_text}\", fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"attention_heatmaps/sample_{i+1}.png\", dpi=300)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "KP0NiG-Zl8jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load all 10 images\n",
        "image_paths = [f\"attention_heatmaps/sample_{i+1}.png\" for i in range(10)]\n",
        "images = [Image.open(p) for p in image_paths]\n",
        "\n",
        "# Get individual image size (assumes all are same size)\n",
        "img_width, img_height = images[0].size\n",
        "\n",
        "# Define grid (e.g. 3 rows × 4 columns = 12 slots, we’ll only use 10)\n",
        "cols = 5\n",
        "rows = 2\n",
        "\n",
        "# Create a blank canvas for the collage\n",
        "grid_width = cols * img_width\n",
        "grid_height = rows * img_height\n",
        "collage = Image.new('RGB', (grid_width, grid_height), color='white')\n",
        "\n",
        "# Paste images into grid\n",
        "for idx, image in enumerate(images):\n",
        "    x = (idx % cols) * img_width\n",
        "    y = (idx // cols) * img_height\n",
        "    collage.paste(image, (x, y))\n",
        "\n",
        "# Save combined image\n",
        "output_path = \"attention_heatmaps/combined_heatmaps.png\"\n",
        "collage.save(output_path)\n",
        "\n",
        "print(f\"Combined image saved to {output_path}\")\n"
      ],
      "metadata": {
        "id": "rT2Yc5rEl_jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Values in Heatmap**"
      ],
      "metadata": {
        "id": "Wp4XEk90MU7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def plot_attention_heatmap(input_text, output_text, attention_weights):\n",
        "    \"\"\"\n",
        "    Visualize attention weights between input and output tokens.\n",
        "\n",
        "    Parameters:\n",
        "    - input_text: str\n",
        "    - output_text: str\n",
        "    - attention_weights: List[List[float]], shape (output_len, input_len)\n",
        "    \"\"\"\n",
        "    sns.set(style=\"white\")\n",
        "\n",
        "    input_chars = list(input_text)\n",
        "    output_chars = list(output_text)\n",
        "\n",
        "    fig_width = max(6, len(input_chars) * 0.5)\n",
        "    fig_height = max(4, len(output_chars) * 0.5)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "\n",
        "    sns.heatmap(\n",
        "        np.array(attention_weights),\n",
        "        xticklabels=input_chars,\n",
        "        yticklabels=output_chars,\n",
        "        cmap='rocket',  # Try 'viridis', 'YlGnBu', 'magma'\n",
        "        cbar=True,\n",
        "        linewidths=0,\n",
        "        square=True,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel(\"Input (Latin)\", fontsize=12, weight='bold')\n",
        "    ax.set_ylabel(\"Output (Marathi)\", fontsize=12, weight='bold')\n",
        "    ax.set_title(\"Attention\", fontsize=14, weight='bold', pad=12)\n",
        "\n",
        "    ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
        "    ax.tick_params(axis='y', rotation=0, labelsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gf4cFWnsmDBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention_heatmap(\n",
        "    input_text=\"barechda\",\n",
        "    output_text=\"बरेचदा\",\n",
        "    attention_weights=attn_weights)"
      ],
      "metadata": {
        "id": "nRYgpA6xmEcH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}